{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ca98ff38f425f4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118  # Version for rtx3090",
   "id": "3c4a4a27d467483b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T12:33:20.797187Z",
     "start_time": "2025-06-09T12:33:20.787017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from test_data_gen import generate_synthetic_dataset\n",
    "\n",
    "NUMBER_OF_RECORDS = 200\n",
    "VECTOR_DIMENSION = 30\n",
    "\n",
    "synthetic_dataset = generate_synthetic_dataset(\n",
    "    number_of_records=NUMBER_OF_RECORDS,\n",
    "    vector_dimension=VECTOR_DIMENSION\n",
    ")\n",
    "synthetic_dataset[50]"
   ],
   "id": "ab63280958928dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Как работает GPS?',\n",
       " 'response': 'Система глобального позиционирования (GPS) использует сигналы от спутников для определения точного местоположения приёмника на Земле путем трилатерации.',\n",
       " 'custom_vector': [0.9241718649864197,\n",
       "  0.8862757086753845,\n",
       "  0.9418854117393494,\n",
       "  0.8010405898094177,\n",
       "  0.9979512691497803,\n",
       "  0.9523987174034119,\n",
       "  0.9858677387237549,\n",
       "  0.8162245750427246,\n",
       "  0.9277184009552002,\n",
       "  0.8832427263259888,\n",
       "  0.12798306345939636,\n",
       "  0.1623060256242752,\n",
       "  0.04388086497783661,\n",
       "  0.11491576582193375,\n",
       "  0.08334853500127792,\n",
       "  0.07457728683948517,\n",
       "  0.0013142724055796862,\n",
       "  0.06693758070468903,\n",
       "  0.18873128294944763,\n",
       "  0.12715288996696472,\n",
       "  0.038583215326070786,\n",
       "  0.09092347323894501,\n",
       "  0.0837830901145935,\n",
       "  0.01080994587391615,\n",
       "  0.1938796192407608,\n",
       "  0.13350287079811096,\n",
       "  0.01674053631722927,\n",
       "  0.005774518009275198,\n",
       "  0.1798594743013382,\n",
       "  0.07867621630430222]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T12:34:44.236554Z",
     "start_time": "2025-06-09T12:33:24.606181Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install unsloth",
   "id": "d59634d321abb2bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.6.1-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.6.1 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.6.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting torch<=2.7.0,>=2.4.0 (from unsloth)\n",
      "  Using cached torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.30-cp312-cp312-win_amd64.whl.metadata (1.3 kB)\n",
      "Collecting bitsandbytes (from unsloth)\n",
      "  Downloading bitsandbytes-0.46.0-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Collecting triton-windows (from unsloth)\n",
      "  Downloading triton_windows-3.3.1.post19-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from unsloth) (25.0)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-0.9.24-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3 (from unsloth)\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: datasets>=3.4.1 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from unsloth) (3.6.0)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: tqdm in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from unsloth) (7.0.0)\n",
      "Collecting wheel>=0.42.0 (from unsloth)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from unsloth) (2.3.0)\n",
      "Collecting accelerate>=0.34.1 (from unsloth)\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
      "  Downloading trl-0.18.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
      "  Using cached peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting protobuf<4.0.0 (from unsloth)\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: huggingface_hub in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from unsloth) (0.32.4)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Using cached hf_transfer-0.1.9-cp38-abi3-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Using cached diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.22.1-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch<=2.7.0,>=2.4.0->unsloth) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch<=2.7.0,>=2.4.0->unsloth) (4.14.0)\n",
      "Collecting sympy>=1.13.3 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch<=2.7.0,>=2.4.0->unsloth) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch<=2.7.0,>=2.4.0->unsloth) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch<=2.7.0,>=2.4.0->unsloth) (80.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
      "Collecting safetensors>=0.4.3 (from accelerate>=0.34.1->unsloth)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from datasets>=3.4.1->unsloth) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from datasets>=3.4.1->unsloth) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from datasets>=3.4.1->unsloth) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from datasets>=3.4.1->unsloth) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from datasets>=3.4.1->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from datasets>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (3.12.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (2025.4.26)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from tqdm->unsloth) (0.4.6)\n",
      "Collecting regex!=2019.12.17 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3->unsloth)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3->unsloth)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.6.1->unsloth)\n",
      "  Using cached cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting pillow (from unsloth_zoo>=2025.6.1->unsloth)\n",
      "  Using cached pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.6.1->unsloth)\n",
      "  Using cached msgspec-0.19.0-cp312-cp312-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting importlib-metadata (from diffusers->unsloth)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata->diffusers->unsloth)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from jinja2->torch<=2.7.0,>=2.4.0->unsloth) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from pandas->datasets>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth) (1.17.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Using cached torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1.0 (from tyro->unsloth)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Using cached shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.3-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro->unsloth)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from rich>=11.1.0->tyro->unsloth) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading unsloth-2025.6.1-py3-none-any.whl (276 kB)\n",
      "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Using cached torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Using cached peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 3.4/6.3 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 10.2 MB/s eta 0:00:00\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 5.5/10.5 MB 55.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.7/10.5 MB 29.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 27.2 MB/s eta 0:00:00\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading trl-0.18.1-py3-none-any.whl (366 kB)\n",
      "Downloading unsloth_zoo-2025.6.1-py3-none-any.whl (147 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading xformers-0.0.30-cp312-cp312-win_amd64.whl (108.0 MB)\n",
      "   ---------------------------------------- 0.0/108.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 3.1/108.0 MB 15.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 6.0/108.0 MB 14.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 8.1/108.0 MB 14.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 11.5/108.0 MB 13.9 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 13.6/108.0 MB 13.4 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 16.0/108.0 MB 13.1 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 17.8/108.0 MB 12.6 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 19.7/108.0 MB 12.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 21.2/108.0 MB 11.7 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 23.1/108.0 MB 11.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 24.6/108.0 MB 11.1 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 26.5/108.0 MB 10.9 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 28.3/108.0 MB 10.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 30.1/108.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 32.0/108.0 MB 10.5 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 33.8/108.0 MB 10.4 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 35.9/108.0 MB 10.4 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 37.7/108.0 MB 10.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 39.6/108.0 MB 10.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 41.7/108.0 MB 10.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 43.5/108.0 MB 10.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 45.6/108.0 MB 10.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 47.4/108.0 MB 10.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 49.3/108.0 MB 10.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 51.4/108.0 MB 10.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 53.5/108.0 MB 10.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 55.3/108.0 MB 10.1 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 57.1/108.0 MB 10.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 59.2/108.0 MB 10.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 61.1/108.0 MB 10.0 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 63.2/108.0 MB 10.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 65.0/108.0 MB 10.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 67.1/108.0 MB 10.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 68.9/108.0 MB 10.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 71.0/108.0 MB 10.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 72.9/108.0 MB 10.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 75.0/108.0 MB 10.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 76.8/108.0 MB 10.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 78.9/108.0 MB 9.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 80.7/108.0 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 82.8/108.0 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 84.9/108.0 MB 9.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 86.8/108.0 MB 9.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 88.9/108.0 MB 9.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 90.7/108.0 MB 9.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 92.8/108.0 MB 9.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 94.9/108.0 MB 9.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 96.7/108.0 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 98.8/108.0 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 100.9/108.0 MB 9.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 103.0/108.0 MB 9.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 104.9/108.0 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  106.7/108.0 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 108.0/108.0 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading bitsandbytes-0.46.0-py3-none-win_amd64.whl (66.5 MB)\n",
      "   ---------------------------------------- 0.0/66.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 2.1/66.5 MB 10.7 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 4.2/66.5 MB 10.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 6.3/66.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 8.4/66.5 MB 10.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 10.5/66.5 MB 10.2 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 12.6/66.5 MB 10.2 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 14.7/66.5 MB 10.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 17.0/66.5 MB 10.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 19.1/66.5 MB 10.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 21.2/66.5 MB 10.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 23.6/66.5 MB 10.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 26.0/66.5 MB 10.6 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 28.3/66.5 MB 10.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 30.7/66.5 MB 10.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 33.0/66.5 MB 10.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 35.4/66.5 MB 10.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 38.0/66.5 MB 11.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 40.6/66.5 MB 11.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 43.3/66.5 MB 11.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 45.9/66.5 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 48.5/66.5 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 51.4/66.5 MB 11.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 54.3/66.5 MB 11.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 57.1/66.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 60.0/66.5 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 63.2/66.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  65.3/66.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 66.5/66.5 MB 11.7 MB/s eta 0:00:00\n",
      "Using cached cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Using cached diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
      "Using cached hf_transfer-0.1.9-cp38-abi3-win_amd64.whl (1.2 MB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached msgspec-0.19.0-cp312-cp312-win_amd64.whl (187 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.6/2.0 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 7.1 MB/s eta 0:00:00\n",
      "Using cached pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Using cached torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Downloading triton_windows-3.3.1.post19-cp312-cp312-win_amd64.whl (41.9 MB)\n",
      "   ---------------------------------------- 0.0/41.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.6/41.9 MB 8.4 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.1/41.9 MB 8.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.0/41.9 MB 8.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.6/41.9 MB 8.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 8.4/41.9 MB 8.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 10.0/41.9 MB 8.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 11.8/41.9 MB 8.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 13.6/41.9 MB 8.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 15.5/41.9 MB 8.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 17.0/41.9 MB 8.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.9/41.9 MB 8.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 21.0/41.9 MB 8.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 22.5/41.9 MB 8.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 24.4/41.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 26.2/41.9 MB 8.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 28.0/41.9 MB 8.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 29.9/41.9 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.7/41.9 MB 8.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.8/41.9 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 35.7/41.9 MB 8.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 37.5/41.9 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 39.3/41.9 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.4/41.9 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.9/41.9 MB 8.8 MB/s eta 0:00:00\n",
      "Downloading tyro-0.9.24-py3-none-any.whl (128 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading typeguard-4.4.3-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: sentencepiece, mpmath, zipp, wheel, typeguard, triton-windows, sympy, shtab, safetensors, regex, protobuf, pillow, networkx, msgspec, mdurl, hf_transfer, docstring-parser, torch, markdown-it-py, importlib-metadata, xformers, torchvision, tokenizers, rich, diffusers, cut_cross_entropy, bitsandbytes, accelerate, tyro, transformers, trl, peft, unsloth_zoo, unsloth\n",
      "\n",
      "   - --------------------------------------  1/34 [mpmath]\n",
      "   --- ------------------------------------  3/34 [wheel]\n",
      "   ----- ----------------------------------  5/34 [triton-windows]\n",
      "   ----- ----------------------------------  5/34 [triton-windows]\n",
      "   ----- ----------------------------------  5/34 [triton-windows]\n",
      "   ----- ----------------------------------  5/34 [triton-windows]\n",
      "   ----- ----------------------------------  5/34 [triton-windows]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ------- --------------------------------  6/34 [sympy]\n",
      "   ----------- ---------------------------- 10/34 [protobuf]\n",
      "   ------------ --------------------------- 11/34 [pillow]\n",
      "   -------------- ------------------------- 12/34 [networkx]\n",
      "   -------------- ------------------------- 12/34 [networkx]\n",
      "   -------------- ------------------------- 12/34 [networkx]\n",
      "   -------------- ------------------------- 12/34 [networkx]\n",
      "   -------------- ------------------------- 12/34 [networkx]\n",
      "   -------------- ------------------------- 12/34 [networkx]\n",
      "   -------------- ------------------------- 12/34 [networkx]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   -------------------- ------------------- 17/34 [torch]\n",
      "   --------------------- ------------------ 18/34 [markdown-it-py]\n",
      "   ----------------------- ---------------- 20/34 [xformers]\n",
      "   ----------------------- ---------------- 20/34 [xformers]\n",
      "   ----------------------- ---------------- 20/34 [xformers]\n",
      "   ----------------------- ---------------- 20/34 [xformers]\n",
      "   ----------------------- ---------------- 20/34 [xformers]\n",
      "   ----------------------- ---------------- 20/34 [xformers]\n",
      "   ----------------------- ---------------- 20/34 [xformers]\n",
      "   ------------------------ --------------- 21/34 [torchvision]\n",
      "   ------------------------ --------------- 21/34 [torchvision]\n",
      "   ------------------------ --------------- 21/34 [torchvision]\n",
      "   ------------------------ --------------- 21/34 [torchvision]\n",
      "   --------------------------- ------------ 23/34 [rich]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ---------------------------- ----------- 24/34 [diffusers]\n",
      "   ----------------------------- ---------- 25/34 [cut_cross_entropy]\n",
      "   ------------------------------ --------- 26/34 [bitsandbytes]\n",
      "   ------------------------------ --------- 26/34 [bitsandbytes]\n",
      "   ------------------------------ --------- 26/34 [bitsandbytes]\n",
      "   ------------------------------ --------- 26/34 [bitsandbytes]\n",
      "   ------------------------------- -------- 27/34 [accelerate]\n",
      "   ------------------------------- -------- 27/34 [accelerate]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ---------------------------------- ----- 29/34 [transformers]\n",
      "   ----------------------------------- ---- 30/34 [trl]\n",
      "   ------------------------------------ --- 31/34 [peft]\n",
      "   ------------------------------------ --- 31/34 [peft]\n",
      "   -------------------------------------- - 33/34 [unsloth]\n",
      "   -------------------------------------- - 33/34 [unsloth]\n",
      "   ---------------------------------------- 34/34 [unsloth]\n",
      "\n",
      "Successfully installed accelerate-1.7.0 bitsandbytes-0.46.0 cut_cross_entropy-25.1.1 diffusers-0.33.1 docstring-parser-0.16 hf_transfer-0.1.9 importlib-metadata-8.7.0 markdown-it-py-3.0.0 mdurl-0.1.2 mpmath-1.3.0 msgspec-0.19.0 networkx-3.5 peft-0.15.2 pillow-11.2.1 protobuf-3.20.3 regex-2024.11.6 rich-14.0.0 safetensors-0.5.3 sentencepiece-0.2.0 shtab-1.7.2 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.0 torchvision-0.22.0 transformers-4.52.4 triton-windows-3.3.1.post19 trl-0.18.1 typeguard-4.4.3 tyro-0.9.24 unsloth-2025.6.1 unsloth_zoo-2025.6.1 wheel-0.45.1 xformers-0.0.30 zipp-3.23.0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T13:07:39.925075Z",
     "start_time": "2025-06-09T13:07:38.702522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def check_gpu_availability() -> None:\n",
    "    \"\"\"\n",
    "    Checks for the availability of a CUDA-enabled GPU and prints its status.\n",
    "    \"\"\"\n",
    "    # Check if a CUDA-enabled GPU is available\n",
    "    is_gpu_available: bool = torch.cuda.is_available()\n",
    "\n",
    "    if is_gpu_available:\n",
    "        # Get the number of available GPUs\n",
    "        gpu_count: int = torch.cuda.device_count()\n",
    "        # Get the name of the current GPU\n",
    "        current_gpu_name: str = torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "        print(f\"✅ GPU доступен.\")\n",
    "        print(f\"Количество GPU: {gpu_count}\")\n",
    "        print(f\"Имя устройства: {current_gpu_name}\")\n",
    "    else:\n",
    "        print(\"❌ GPU не доступен. PyTorch будет использовать CPU.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    check_gpu_availability()"
   ],
   "id": "d9bd7c0a6fc467d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU доступен.\n",
      "Количество GPU: 1\n",
      "Имя устройства: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T13:06:51.218312Z",
     "start_time": "2025-06-09T13:06:50.352971Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2fe71776c703b662",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision==0.21.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: torchaudio==2.6.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch==2.6.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch==2.6.0) (4.14.0)\n",
      "Requirement already satisfied: networkx in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch==2.6.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch==2.6.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch==2.6.0) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch==2.6.0) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torch==2.6.0) (1.13.1)\n",
      "Requirement already satisfied: numpy in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torchvision==0.21.0) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from torchvision==0.21.0) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\my_projects\\feelent\\.venv\\lib\\site-packages (from jinja2->torch==2.6.0) (3.0.2)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T14:16:20.573592Z",
     "start_time": "2025-06-16T14:16:12.824760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "# Unsloth, Transformers, TRL and PEFT imports\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import TrainingArguments, PreTrainedModel\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "import torch.nn as nn\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. MODEL LOADING (Updated for Qwen3 1.7B)\n",
    "# ==============================================================================\n",
    "# We will load the 4-bit quantized version of Qwen3-1.7B-Instruct from Unsloth.\n",
    "# Create a folder named 'model_cache' in your project directory\n",
    "model_cache_path: str = \"./model_cache\"\n",
    "\n",
    "max_seq_length: int = 2048\n",
    "dtype = None # Let Unsloth auto-select the best dtype (float16 or bfloat16)\n",
    "load_in_4bit: bool = True\n",
    "\n",
    "print(\"==> Step 1: Loading the Qwen3-1.7B model...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/qwen3-1.7b-instruct-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    cache_dir = model_cache_path, # <-- ВОТ ЭТОТ ПАРАМЕТР\n",
    ")\n",
    "print(\"==> Model loaded successfully!\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. CUSTOM MODEL WRAPPER (No changes needed)\n",
    "# ==============================================================================\n",
    "# This wrapper class is generic and works with any model.\n",
    "\n",
    "class ConditionalLM(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    A custom model that wraps a pre-trained language model and adds a conditional projection layer.\n",
    "    \"\"\"\n",
    "    supports_gradient_checkpointing = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        language_model: PreTrainedModel,\n",
    "        custom_vector_size: int\n",
    "    ):\n",
    "        super().__init__(language_model.config)\n",
    "        self.language_model = language_model\n",
    "        self.custom_vector_size = custom_vector_size\n",
    "        self.embedding_size = self.language_model.get_input_embeddings().embedding_dim\n",
    "        self.projection_layer = nn.Sequential(\n",
    "            nn.Linear(self.custom_vector_size, self.embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.embedding_size, self.embedding_size)\n",
    "        )\n",
    "\n",
    "    def get_input_embeddings(self) -> nn.Embedding:\n",
    "        return self.language_model.get_input_embeddings()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.LongTensor] = None,\n",
    "        custom_vector: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        **kwargs,\n",
    "    ) -> CausalLMOutputWithPast:\n",
    "        if custom_vector is None:\n",
    "            return self.language_model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, labels=labels,\n",
    "                inputs_embeds=inputs_embeds, **kwargs\n",
    "            )\n",
    "        projected_vector = self.projection_layer(custom_vector).unsqueeze(1)\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.get_input_embeddings()(input_ids)\n",
    "        inputs_embeds = torch.cat([projected_vector, inputs_embeds], dim=1)\n",
    "        new_attention_mask = None\n",
    "        if attention_mask is not None:\n",
    "            projected_vector_mask = torch.ones(\n",
    "                attention_mask.shape[0], 1, dtype=attention_mask.dtype, device=attention_mask.device\n",
    "            )\n",
    "            new_attention_mask = torch.cat([projected_vector_mask, attention_mask], dim=1)\n",
    "        new_labels = None\n",
    "        if labels is not None:\n",
    "            projected_vector_label = torch.full(\n",
    "                (labels.shape[0], 1), -100, dtype=labels.dtype, device=labels.device\n",
    "            )\n",
    "            new_labels = torch.cat([projected_vector_label, labels], dim=1)\n",
    "        return self.language_model(\n",
    "            inputs_embeds=inputs_embeds, attention_mask=new_attention_mask,\n",
    "            labels=new_labels, **kwargs\n",
    "        )\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. DATA GENERATION AND PREPARATION (No changes needed)\n",
    "# ==============================================================================\n",
    "# The data generation and formatting functions remain the same.\n",
    "\n",
    "def generate_synthetic_dataset(number_of_records: int, vector_dimension: int) -> Dataset:\n",
    "    # (The function body is the same as before, so it is omitted here for brevity)\n",
    "    if vector_dimension % 3 != 0: raise ValueError(\"vector_dimension must be divisible by 3.\")\n",
    "    source_data: Dict[str, List[Tuple[str, str]]] = {\n",
    "        \"science\": [(\"Что такое черная дыра?\", \"Чёрная дыра — это область пространства-времени, гравитационное притяжение которой настолько велико, что покинуть её не могут даже объекты, движущиеся со скоростью света.\"), (\"Объясни фотосинтез.\", \"Фотосинтез — это сложный химический процесс преобразования энергии видимого света в энергию химических связей органических веществ.\"),],\n",
    "        \"history\": [(\"Расскажи о Ренессансе.\", \"Эпоха Возрождения, или Ренессанс, — это период в истории культуры Европы, пришедший на смену Средним векам и предшествующий Просвещению.\"), (\"Кто такой Юлий Цезарь?\", \"Гай Юлий Цезарь был древнеримским государственным и политическим деятелем, полководцем и писателем.\"),],\n",
    "        \"creative\": [(\"Придумай шутку про программиста.\", \"Почему программисты так не любят природу? Слишком много багов.\"), (\"Напиши короткий стих о космосе.\", \"Средь миллиардов звёздных троп, летит бесшумно телескоп. Он ищет дом, он ищет свет, вдали от суетных планет.\"),],\n",
    "    }\n",
    "    records_list: List[Dict[str, Any]] = []\n",
    "    categories: List[str] = list(source_data.keys())\n",
    "    chunk_size: int = vector_dimension // 3\n",
    "    for _ in range(number_of_records):\n",
    "        chosen_category: str = random.choice(categories)\n",
    "        prompt, response = random.choice(source_data[chosen_category])\n",
    "        custom_vector = np.zeros(vector_dimension, dtype=np.float32)\n",
    "        for i in range(3):\n",
    "            start_index, end_index = i * chunk_size, (i + 1) * chunk_size\n",
    "            custom_vector[start_index:end_index] = np.random.uniform(0.0, 0.2, size=chunk_size)\n",
    "        category_index = categories.index(chosen_category)\n",
    "        start_index, end_index = category_index * chunk_size, (category_index + 1) * chunk_size\n",
    "        custom_vector[start_index:end_index] = np.random.uniform(0.8, 1.0, size=chunk_size)\n",
    "        records_list.append({\"prompt\": prompt, \"response\": response, \"custom_vector\": custom_vector})\n",
    "    return Dataset.from_list(records_list)\n",
    "\n",
    "def formatting_prompts_func(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    text_parts = [\n",
    "        f\"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n\",\n",
    "        f\"<|im_start|>user\\n{example['prompt']}<|im_end|>\\n\",\n",
    "        f\"<|im_start|>assistant\\n{example['response']}<|im_end|>\"\n",
    "    ]\n",
    "    example[\"text\"] = \"\".join(text_parts) + tokenizer.eos_token\n",
    "    return example\n",
    "\n",
    "class ConditionalDataCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            [f[\"text\"] for f in features], return_tensors=\"pt\", padding=True,\n",
    "            truncation=True, max_length=max_seq_length\n",
    "        )\n",
    "        custom_vectors = torch.tensor([f[\"custom_vector\"] for f in features], dtype=torch.float)\n",
    "        tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].clone()\n",
    "        tokenized_inputs[\"custom_vector\"] = custom_vectors\n",
    "        return tokenized_inputs\n",
    "\n",
    "print(\"==> Step 3: Generating and preparing dataset...\")\n",
    "NUMBER_OF_RECORDS = 200\n",
    "VECTOR_DIMENSION = 30\n",
    "synthetic_dataset = generate_synthetic_dataset(\n",
    "    number_of_records=NUMBER_OF_RECORDS, vector_dimension=VECTOR_DIMENSION\n",
    ")\n",
    "processed_dataset = synthetic_dataset.map(formatting_prompts_func, num_proc=4)\n",
    "print(\"==> Dataset prepared successfully!\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. TRAINING SETUP (Updated for Qwen3)\n",
    "# ==============================================================================\n",
    "print(\"==> Step 4: Setting up the training components...\")\n",
    "custom_model = ConditionalLM(language_model=model, custom_vector_size=VECTOR_DIMENSION)\n",
    "\n",
    "# LoRA configuration for Qwen3\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # NOTE: We assume these are the correct modules for Qwen3,\n",
    "    # as they are standard for Qwen1.5 and Qwen2. This is an educated guess.\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    modules_to_save=[\"projection_layer\"], # Don't forget our custom layer!\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"qwen3_1.7b_conditional_finetune\", # <-- Updated output directory\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=5,\n",
    "    max_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    logging_steps=1,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "data_collator = ConditionalDataCollator(tokenizer=tokenizer)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=custom_model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=processed_dataset,\n",
    "    peft_config=lora_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "print(\"==> Trainer is ready for Qwen3 1.7B!\\n\")\n",
    "print(\"To start training, run the command: trainer.train()\")"
   ],
   "id": "1f8feba43ec693f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.6.0+cu118)\n",
      "    Python  3.12.10 (you have 3.12.10)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==> Step 1: Loading the Qwen3-1.7B model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:339: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE}:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "unsloth/qwen3-1.7b-instruct-bnb-4bit/*.json (repository not found)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mHTTPError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001B[39m, in \u001B[36mhf_raise_for_status\u001B[39m\u001B[34m(response, endpoint_name)\u001B[39m\n\u001B[32m    408\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m409\u001B[39m     \u001B[43mresponse\u001B[49m\u001B[43m.\u001B[49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    410\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\requests\\models.py:1024\u001B[39m, in \u001B[36mResponse.raise_for_status\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1023\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[32m-> \u001B[39m\u001B[32m1024\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response=\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[31mHTTPError\u001B[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/unsloth/qwen3-1.7b-instruct-bnb-4bit",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRepositoryNotFoundError\u001B[39m                   Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\huggingface_hub\\hf_file_system.py:125\u001B[39m, in \u001B[36mHfFileSystem._repo_and_revision_exist\u001B[39m\u001B[34m(self, repo_type, repo_id, revision)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_api\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrepo_info\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    126\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconstants\u001B[49m\u001B[43m.\u001B[49m\u001B[43mHF_HUB_ETAG_TIMEOUT\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (RepositoryNotFoundError, HFValidationError) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001B[39m, in \u001B[36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    112\u001B[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001B[34m__name__\u001B[39m, has_token=has_token, kwargs=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:2816\u001B[39m, in \u001B[36mHfApi.repo_info\u001B[39m\u001B[34m(self, repo_id, revision, repo_type, timeout, files_metadata, expand, token)\u001B[39m\n\u001B[32m   2815\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mUnsupported repo type.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m2816\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2817\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2818\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2819\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2820\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2821\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexpand\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexpand\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m   2822\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfiles_metadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfiles_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2823\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001B[39m, in \u001B[36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    112\u001B[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001B[34m__name__\u001B[39m, has_token=has_token, kwargs=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:2601\u001B[39m, in \u001B[36mHfApi.model_info\u001B[39m\u001B[34m(self, repo_id, revision, timeout, securityStatus, files_metadata, expand, token)\u001B[39m\n\u001B[32m   2600\u001B[39m r = get_session().get(path, headers=headers, timeout=timeout, params=params)\n\u001B[32m-> \u001B[39m\u001B[32m2601\u001B[39m \u001B[43mhf_raise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2602\u001B[39m data = r.json()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:459\u001B[39m, in \u001B[36mhf_raise_for_status\u001B[39m\u001B[34m(response, endpoint_name)\u001B[39m\n\u001B[32m    450\u001B[39m     message = (\n\u001B[32m    451\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse.status_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m Client Error.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    452\u001B[39m         + \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    457\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m https://huggingface.co/docs/huggingface_hub/authentication\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    458\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m459\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m _format(RepositoryNotFoundError, message, response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m response.status_code == \u001B[32m400\u001B[39m:\n",
      "\u001B[31mRepositoryNotFoundError\u001B[39m: 401 Client Error. (Request ID: Root=1-68502738-4151393d0aaed9182b182465;48ea1803-59d2-4f81-9bce-21d635a4ef66)\n\nRepository Not Found for url: https://huggingface.co/api/models/unsloth/qwen3-1.7b-instruct-bnb-4bit.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 29\u001B[39m\n\u001B[32m     26\u001B[39m load_in_4bit: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     28\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m==> Step 1: Loading the Qwen3-1.7B model...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m model, tokenizer = \u001B[43mFastLanguageModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     30\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43munsloth/qwen3-1.7b-instruct-bnb-4bit\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     31\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     32\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     33\u001B[39m \u001B[43m    \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_cache_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# <-- ВОТ ЭТОТ ПАРАМЕТР\u001B[39;49;00m\n\u001B[32m     35\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     36\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m==> Model loaded successfully!\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     39\u001B[39m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[32m     40\u001B[39m \u001B[38;5;66;03m# 2. CUSTOM MODEL WRAPPER (No changes needed)\u001B[39;00m\n\u001B[32m     41\u001B[39m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[32m     42\u001B[39m \u001B[38;5;66;03m# This wrapper class is generic and works with any model.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\unsloth\\models\\loader.py:199\u001B[39m, in \u001B[36mFastLanguageModel.from_pretrained\u001B[39m\u001B[34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, *args, **kwargs)\u001B[39m\n\u001B[32m    196\u001B[39m     both_exist = exist_adapter_config \u001B[38;5;129;01mand\u001B[39;00m exist_config\n\u001B[32m    197\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    198\u001B[39m     \u001B[38;5;66;03m# Because HfFileSystem assumes linux paths, we need to set the path with forward slashes, even on Windows.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m199\u001B[39m     files = \u001B[43mHfFileSystem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mglob\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmodel_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m/*.json\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    200\u001B[39m     files = (os.path.split(x)[-\u001B[32m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m files)\n\u001B[32m    201\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28msum\u001B[39m(x == \u001B[33m\"\u001B[39m\u001B[33madapter_config.json\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m x == \u001B[33m\"\u001B[39m\u001B[33mconfig.json\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m files) >= \u001B[32m2\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\huggingface_hub\\hf_file_system.py:520\u001B[39m, in \u001B[36mHfFileSystem.glob\u001B[39m\u001B[34m(self, path, **kwargs)\u001B[39m\n\u001B[32m    518\u001B[39m \u001B[38;5;66;03m# Set expand_info=False by default to get a x10 speed boost\u001B[39;00m\n\u001B[32m    519\u001B[39m kwargs = {\u001B[33m\"\u001B[39m\u001B[33mexpand_info\u001B[39m\u001B[33m\"\u001B[39m: kwargs.get(\u001B[33m\"\u001B[39m\u001B[33mdetail\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m), **kwargs}\n\u001B[32m--> \u001B[39m\u001B[32m520\u001B[39m path = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mresolve_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrevision\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m.unresolve()\n\u001B[32m    521\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().glob(path, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\huggingface_hub\\hf_file_system.py:216\u001B[39m, in \u001B[36mHfFileSystem.resolve_path\u001B[39m\u001B[34m(self, path, revision)\u001B[39m\n\u001B[32m    214\u001B[39m     repo_and_revision_exist, _ = \u001B[38;5;28mself\u001B[39m._repo_and_revision_exist(repo_type, repo_id, revision)\n\u001B[32m    215\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m repo_and_revision_exist:\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m         \u001B[43m_raise_file_not_found\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    218\u001B[39m     _raise_file_not_found(path, err)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\.venv\\Lib\\site-packages\\huggingface_hub\\hf_file_system.py:1138\u001B[39m, in \u001B[36m_raise_file_not_found\u001B[39m\u001B[34m(path, err)\u001B[39m\n\u001B[32m   1136\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(err, HFValidationError):\n\u001B[32m   1137\u001B[39m     msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (invalid repository id)\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1138\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: unsloth/qwen3-1.7b-instruct-bnb-4bit/*.json (repository not found)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "44ded371243c612f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T14:05:45.908700Z",
     "start_time": "2025-06-16T14:05:39.501167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from datasets import Dataset\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "from enum import Enum\n",
    "\n",
    "# TRL, Transformers, Unsloth imports\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import PreTrainedModel, AutoTokenizer\n",
    "from trl import PPOTrainer, PPOConfig\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Core Classes (ConditionalLM and InjectionMethod Enum)\n",
    "# ==============================================================================\n",
    "# These are the same classes we finalized before.\n",
    "\n",
    "class InjectionMethod(Enum):\n",
    "    PREPEND_EMBEDDING = \"prepend_embedding\"\n",
    "    ADD_AFTER_LAYER_N = \"add_after_layer_n\"\n",
    "    ADD_TO_EVERY_LAYER = \"add_to_every_layer\"\n",
    "\n",
    "class ConditionalLM(PreTrainedModel):\n",
    "    supports_gradient_checkpointing = True\n",
    "    def __init__(\n",
    "            self,\n",
    "            language_model: PreTrainedModel,\n",
    "            custom_vector_size: int,\n",
    "\n",
    "             injection_method: InjectionMethod = InjectionMethod.PREPEND_EMBEDDING,\n",
    "                 injection_layer_index: Optional[int] = None):\n",
    "        super().__init__(language_model.config)\n",
    "        self.language_model = language_model\n",
    "        self.custom_vector_size = custom_vector_size\n",
    "        self.injection_method = injection_method\n",
    "        self.injection_layer_index = injection_layer_index\n",
    "        self.embedding_size = self.language_model.get_input_embeddings().embedding_dim\n",
    "        self._validate_settings()\n",
    "        self.projection_layer = nn.Sequential(nn.Linear(self.custom_vector_size, self.embedding_size), nn.ReLU(), nn.Linear(self.embedding_size, self.embedding_size))\n",
    "        self.projected_vector_cache: Optional[torch.Tensor] = None\n",
    "        self._register_hooks()\n",
    "    def _validate_settings(self):\n",
    "        if self.injection_method == InjectionMethod.ADD_AFTER_LAYER_N:\n",
    "            if self.injection_layer_index is None: raise ValueError(\"`injection_layer_index` must be set.\")\n",
    "            num_layers = len(self.language_model.model.layers)\n",
    "            if not (0 <= self.injection_layer_index < num_layers): raise ValueError(f\"`injection_layer_index` must be between 0 and {num_layers - 1}.\")\n",
    "    def _register_hooks(self):\n",
    "        if self.injection_method == InjectionMethod.ADD_TO_EVERY_LAYER:\n",
    "            for layer in self.language_model.model.layers: layer.register_forward_hook(self._addition_hook)\n",
    "        elif self.injection_method == InjectionMethod.ADD_AFTER_LAYER_N:\n",
    "            self.language_model.model.layers[self.injection_layer_index].register_forward_hook(self._addition_hook)\n",
    "    def _addition_hook(self, module: nn.Module, inputs: Any, outputs: Any) -> Any:\n",
    "        hidden_states = outputs[0]\n",
    "        modified_hidden_states = hidden_states + self.projected_vector_cache.unsqueeze(1)\n",
    "        return (modified_hidden_states,) + outputs[1:]\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids: Optional[torch.LongTensor] = None,\n",
    "            custom_vector: Optional[torch.Tensor] = None,\n",
    "            **kwargs\n",
    "         ):\n",
    "        if custom_vector is None: return self.language_model(input_ids=input_ids, **kwargs)\n",
    "        if self.injection_method == InjectionMethod.PREPEND_EMBEDDING:\n",
    "            projected_vector = self.projection_layer(custom_vector).unsqueeze(1)\n",
    "            token_embeddings = self.get_input_embeddings()(input_ids)\n",
    "            inputs_embeds = torch.cat([projected_vector, token_embeddings], dim=1)\n",
    "            attention_mask, labels = kwargs.get(\"attention_mask\"), kwargs.get(\"labels\")\n",
    "            if attention_mask is not None:\n",
    "                proj_mask = torch.ones(attention_mask.shape[0], 1, dtype=attention_mask.dtype, device=attention_mask.device)\n",
    "                kwargs[\"attention_mask\"] = torch.cat([proj_mask, attention_mask], dim=1)\n",
    "            if labels is not None:\n",
    "                proj_label = torch.full((labels.shape[0], 1), -100, dtype=labels.dtype, device=labels.device)\n",
    "                kwargs[\"labels\"] = torch.cat([proj_label, labels], dim=1)\n",
    "            return self.language_model(inputs_embeds=inputs_embeds, **kwargs)\n",
    "        elif self.injection_method in [InjectionMethod.ADD_TO_EVERY_LAYER, InjectionMethod.ADD_AFTER_LAYER_N]:\n",
    "            self.projected_vector_cache = self.projection_layer(custom_vector)\n",
    "            outputs = self.language_model(input_ids=input_ids, **kwargs)\n",
    "            self.projected_vector_cache = None\n",
    "            return outputs\n",
    "        else: raise NotImplementedError(f\"Injection method {self.injection_method} is not implemented.\")\n",
    "    def get_input_embeddings(self) -> nn.Embedding: return self.language_model.get_input_embeddings()\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. NEW: Placeholder Reward Model (The Supervisor)\n",
    "# ==============================================================================\n",
    "# In a real project, this would be a separately trained model.\n",
    "# Here, it just returns a random score for any given input.\n",
    "\n",
    "def get_rewards_from_api(\n",
    "    prompts: List[str],\n",
    "    responses: List[str],\n",
    "    api_url: str,\n",
    "    api_token: str,\n",
    "    device: str\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Gets rewards for a batch of prompts and responses from an external API.\n",
    "\n",
    "    Args:\n",
    "        prompts (List[str]): A list of prompts sent to the policy model.\n",
    "        responses (List[str]): A list of responses generated by the policy model.\n",
    "        api_url (str): The endpoint URL of the external reward model.\n",
    "        api_token (str): The authentication token for the API.\n",
    "        device (str): The torch device to place the resulting tensor on.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape (batch_size, 1) with rewards.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    # We assume the API can handle batch requests for efficiency.\n",
    "    # The payload is a list of objects, each with a prompt and a response.\n",
    "    payload = {\n",
    "        \"inputs\": [\n",
    "            {\"prompt\": p, \"response\": r} for p, r in zip(prompts, responses)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    rewards = []\n",
    "    try:\n",
    "        # Make the POST request to the external API\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
    "\n",
    "        # Parse the JSON response\n",
    "        results = response.json()\n",
    "\n",
    "        # We expect the API to return a list of scores\n",
    "        # Example format: {\"scores\": [0.8, 0.2, 0.9, 0.5]}\n",
    "        scores = results.get(\"scores\", [])\n",
    "        if len(scores) != len(prompts):\n",
    "             raise ValueError(\"API returned a different number of scores than expected.\")\n",
    "\n",
    "        rewards = [torch.tensor(score) for score in scores]\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error calling external API: {e}\")\n",
    "        # On error, return a neutral reward (0.0) for the whole batch\n",
    "        rewards = [torch.tensor(0.0) for _ in prompts]\n",
    "\n",
    "    # The PPOTrainer expects a tensor of shape (batch_size,).\n",
    "    return torch.tensor(rewards, dtype=torch.float32, device=device)\n",
    "\n",
    "class PlaceholderRewardModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A placeholder for a real reward model. It returns a random scalar reward.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name_or_path: str):\n",
    "        super().__init__()\n",
    "        # In a real scenario, you might load a model with a scalar output head.\n",
    "        # For this example, we don't need to load anything.\n",
    "        print(f\"Initialized PlaceholderRewardModel. It will return random rewards.\")\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor,\n",
    "        **kwargs,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids (torch.LongTensor): Tokenized sequence of (prompt + response).\n",
    "        Returns:\n",
    "            torch.Tensor: A tensor of shape (batch_size, 1) with random rewards.\n",
    "        \"\"\"\n",
    "        batch_size = input_ids.shape[0]\n",
    "        # Return a random reward for each item in the batch\n",
    "        return torch.randn(batch_size, 1, device=input_ids.device)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Data Generation for PPO\n",
    "# ==============================================================================\n",
    "# For PPO, we only need prompts and their corresponding vectors to start generation.\n",
    "\n",
    "def generate_ppo_dataset(number_of_prompts: int, vector_dimension: int) -> Dataset:\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset of prompts and custom vectors for PPO.\n",
    "    \"\"\"\n",
    "    prompts = [\n",
    "        \"Что такое черная дыра?\", \"Расскажи о Ренессансе.\", \"Придумай шутку про программиста.\",\n",
    "        \"Объясни фотосинтез.\", \"Кто такой Юлий Цезарь?\", \"Напиши короткий стих о космосе.\"\n",
    "    ]\n",
    "    records_list = []\n",
    "    for i in range(number_of_prompts):\n",
    "        records_list.append({\n",
    "            \"prompt\": random.choice(prompts),\n",
    "            # In a real case, the vector would be meaningful. Here, it's random.\n",
    "            \"custom_vector\": np.random.randn(vector_dimension).astype(np.float32)\n",
    "        })\n",
    "    return Dataset.from_list(records_list)\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Main PPO Script Setup\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Configuration ---\n",
    "SFT_MODEL_PATH = \"unsloth/qwen3-1.7b-instruct-bnb-4bit\" # Path to your SFT model\n",
    "BASE_MODEL_NAME = \"unsloth/qwen3-1.7b-instruct-bnb-4bit\"\n",
    "VECTOR_DIMENSION = 30\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "ppo_config = PPOConfig(\n",
    "    batch_size=4,\n",
    "    mini_batch_size=2,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1.4e-6, # Use a very low learning rate for PPO\n",
    "    log_with=\"wandb\", # or \"tensorboard\" or None\n",
    ")\n",
    "\n",
    "# --- Load Base Model and Tokenizer ---\n",
    "print(\"Loading base model and tokenizer...\")\n",
    "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=BASE_MODEL_NAME,\n",
    "    max_seq_length=512,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "# Qwen models need a padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "# --- Initialize Models for PPO ---\n",
    "print(\"Initializing Policy, Reference, and Reward Models...\")\n",
    "\n",
    "# In a real workflow, you would load the weights from your SFT training here.\n",
    "# For this example, we start from the base model.\n",
    "policy_model = ConditionalLM(\n",
    "    language_model=base_model,\n",
    "    custom_vector_size=VECTOR_DIMENSION,\n",
    "    injection_method=InjectionMethod.PREPEND_EMBEDDING,\n",
    ").to(DEVICE)\n",
    "\n",
    "# The reference model is a frozen copy of the policy model before PPO training.\n",
    "ref_model = copy.deepcopy(policy_model)\n",
    "for param in ref_model.parameters():\n",
    "    param.requires_grad = False\n",
    "ref_model.eval()\n",
    "\n",
    "# Our placeholder reward model\n",
    "reward_model = PlaceholderRewardModel(SFT_MODEL_PATH).to(DEVICE)\n",
    "\n",
    "\n",
    "# --- Prepare Dataset and Collator ---\n",
    "print(\"Preparing dataset...\")\n",
    "dataset = generate_ppo_dataset(number_of_prompts=100, vector_dimension=VECTOR_DIMENSION)\n",
    "\n",
    "def collator(data: List[Dict[str, Any]]):\n",
    "    # Collate function to prepare batches for the PPOTrainer\n",
    "    batch = {}\n",
    "    prompts_with_template = [f\"<|im_start|>user\\n{x['prompt']}<|im_end|>\\n<|im_start|>assistant\\n\" for x in data]\n",
    "    batch[\"input_ids\"] = tokenizer(prompts_with_template, padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    batch[\"query\"] = tokenizer.batch_decode(batch[\"input_ids\"])\n",
    "    batch[\"custom_vector\"] = torch.tensor([x['custom_vector'] for x in data], dtype=torch.float32)\n",
    "    return batch\n",
    "\n",
    "# --- Instantiate PPOTrainer ---\n",
    "print(\"Initializing PPOTrainer...\")\n",
    "ppo_trainer = PPOTrainer(\n",
    "    config=ppo_config,\n",
    "    model=policy_model,\n",
    "    ref_model=ref_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=dataset,\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. The PPO Training Loop\n",
    "# ==============================================================================\n",
    "print(\"\\n=== Starting PPO Training Loop ===\\n\")\n",
    "\n",
    "output_min_length = 32\n",
    "output_max_length = 128\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "for step, batch in enumerate(ppo_trainer.dataloader):\n",
    "    if step >= ppo_config.total_ppo_epochs:\n",
    "        break\n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"].to(DEVICE)\n",
    "    custom_vectors = batch[\"custom_vector\"].to(DEVICE)\n",
    "\n",
    "    # --- Generation ---\n",
    "    # Generate responses from the policy model, passing the custom vector\n",
    "    generation_kwargs = {\n",
    "        \"min_length\": -1,\n",
    "        \"top_k\": 0.0,\n",
    "        \"top_p\": 1.0,\n",
    "        \"do_sample\": True,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "        \"custom_vector\": custom_vectors, # Pass our vector here!\n",
    "    }\n",
    "    response_tensors = ppo_trainer.generate(\n",
    "        prompt_tensors,\n",
    "        length_sampler=output_length_sampler,\n",
    "        **generation_kwargs,\n",
    "    )\n",
    "\n",
    "    # The output from generate is the full sequence (prompt + response)\n",
    "    batch[\"response\"] = tokenizer.batch_decode(response_tensors)\n",
    "\n",
    "    # --- Reward Calculation ---\n",
    "    # Prepare input for the reward model: prompt + response\n",
    "    texts_for_reward = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    tokenized_texts_for_reward = tokenizer(texts_for_reward, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    # Get rewards from the supervisor/reward model\n",
    "    # NOTE: In a real scenario, the reward model might also need the custom_vector\n",
    "    rewards = reward_model(input_ids=tokenized_texts_for_reward[\"input_ids\"])\n",
    "\n",
    "    # --- PPO Step ---\n",
    "    # The trainer performs the PPO update.\n",
    "    stats = ppo_trainer.step(prompt_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)\n",
    "\n",
    "    print(f\"--- Step {step+1} ---\")\n",
    "    print(f\"Objective/kl: {stats['objective/kl']:.4f}\")\n",
    "    print(f\"Mean reward: {torch.mean(rewards).item():.4f}\")\n",
    "    print(f\"Example response: {batch['response'][0]}\\n\")\n",
    "\n",
    "print(\"\\n=== PPO Training Finished ===\\n\")"
   ],
   "id": "df75ff36314668c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.6.0+cu118)\n",
      "    Python  3.12.10 (you have 3.12.10)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PPOConfig.__init__() got an unexpected keyword argument 'log_with'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 207\u001B[39m\n\u001B[32m    204\u001B[39m VECTOR_DIMENSION = \u001B[32m30\u001B[39m\n\u001B[32m    205\u001B[39m DEVICE = \u001B[33m\"\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m207\u001B[39m ppo_config = \u001B[43mPPOConfig\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    208\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    209\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmini_batch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    210\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgradient_accumulation_steps\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    211\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1.4e-6\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Use a very low learning rate for PPO\u001B[39;49;00m\n\u001B[32m    212\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlog_with\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mwandb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# or \"tensorboard\" or None\u001B[39;49;00m\n\u001B[32m    213\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m    215\u001B[39m \u001B[38;5;66;03m# --- Load Base Model and Tokenizer ---\u001B[39;00m\n\u001B[32m    216\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mLoading base model and tokenizer...\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my_projects\\Feelent\\model_tests\\unsloth_compiled_cache\\UnslothPPOTrainer.py:269\u001B[39m, in \u001B[36mUnslothPPOConfig.__init__\u001B[39m\u001B[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices, dataset_num_proc, num_mini_batches, total_episodes, local_rollout_forward_batch_size, num_sample_generations, response_length, stop_token, stop_token_id, temperature, missing_eos_penalty, sft_model_path, world_size, num_total_batches, micro_batch_size, local_batch_size, batch_size, local_mini_batch_size, mini_batch_size, exp_name, reward_model_path, model_adapter_name, ref_adapter_name, num_ppo_epochs, whiten_rewards, kl_coef, kl_estimator, cliprange, vf_coef, cliprange_value, gamma, lam, ds3_gather_for_generation, vllm_sampling_params, unsloth_num_chunks, **kwargs)\u001B[39m\n\u001B[32m    266\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmultiprocessing\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m cpu_count\n\u001B[32m    267\u001B[39m     dataset_num_proc = cpu_count()\n\u001B[32m--> \u001B[39m\u001B[32m269\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    270\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    271\u001B[39m \u001B[43m    \u001B[49m\u001B[43moverwrite_output_dir\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43moverwrite_output_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    272\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdo_train\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    273\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdo_eval\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    274\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdo_predict\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_predict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    275\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_strategy\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    276\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    277\u001B[39m \u001B[43m    \u001B[49m\u001B[43mper_device_train_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_device_train_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    278\u001B[39m \u001B[43m    \u001B[49m\u001B[43mper_device_eval_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_device_eval_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    279\u001B[39m \u001B[43m    \u001B[49m\u001B[43mper_gpu_train_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_gpu_train_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    280\u001B[39m \u001B[43m    \u001B[49m\u001B[43mper_gpu_eval_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_gpu_eval_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    281\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgradient_accumulation_steps\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient_accumulation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    282\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_accumulation_steps\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_accumulation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    283\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_delay\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_delay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtorch_empty_cache_steps\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_empty_cache_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    285\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    286\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    287\u001B[39m \u001B[43m    \u001B[49m\u001B[43madam_beta1\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43madam_beta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    288\u001B[39m \u001B[43m    \u001B[49m\u001B[43madam_beta2\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43madam_beta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    289\u001B[39m \u001B[43m    \u001B[49m\u001B[43madam_epsilon\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43madam_epsilon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    290\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_grad_norm\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_grad_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    291\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_train_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_train_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    292\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_steps\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    293\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlr_scheduler_type\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    294\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwarmup_ratio\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarmup_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    295\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwarmup_steps\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarmup_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    296\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlog_level\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_level\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    297\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlog_level_replica\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_level_replica\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    298\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlog_on_each_node\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_on_each_node\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    299\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlogging_dir\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogging_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    300\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlogging_strategy\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogging_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    301\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlogging_first_step\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogging_first_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    302\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlogging_steps\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogging_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    303\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlogging_nan_inf_filter\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogging_nan_inf_filter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    304\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_strategy\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    305\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_steps\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    306\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_total_limit\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_total_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_safetensors\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_safetensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    308\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_on_each_node\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_on_each_node\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    309\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_only_model\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_only_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    310\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrestore_callback_states_from_checkpoint\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mrestore_callback_states_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m    \u001B[49m\u001B[43mno_cuda\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mno_cuda\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cpu\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cpu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_mps_device\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_mps_device\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[43m    \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    315\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdata_seed\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m    \u001B[49m\u001B[43mjit_mode_eval\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mjit_mode_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_ipex\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_ipex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbf16\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mbf16\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfp16\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp16\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfp16_opt_level\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp16_opt_level\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    321\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhalf_precision_backend\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mhalf_precision_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    322\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbf16_full_eval\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mbf16_full_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    323\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfp16_full_eval\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp16_full_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    324\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtf32\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf32\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    325\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocal_rank\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    326\u001B[39m \u001B[43m    \u001B[49m\u001B[43mddp_backend\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mddp_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    327\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtpu_num_cores\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtpu_num_cores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    328\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtpu_metrics_debug\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtpu_metrics_debug\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    329\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdebug\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdebug\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    330\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataloader_drop_last\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_drop_last\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    331\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_steps\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    332\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataloader_num_workers\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_num_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    333\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataloader_prefetch_factor\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_prefetch_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    334\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpast_index\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mpast_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    335\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    336\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdisable_tqdm\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisable_tqdm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    337\u001B[39m \u001B[43m    \u001B[49m\u001B[43mremove_unused_columns\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mremove_unused_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    338\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabel_names\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    339\u001B[39m \u001B[43m    \u001B[49m\u001B[43mload_best_model_at_end\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_best_model_at_end\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    340\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetric_for_best_model\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_for_best_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    341\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgreater_is_better\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mgreater_is_better\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    342\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_data_skip\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_data_skip\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    343\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfsdp\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfsdp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    344\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfsdp_min_num_params\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfsdp_min_num_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    345\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfsdp_config\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfsdp_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    346\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfsdp_transformer_layer_cls_to_wrap\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfsdp_transformer_layer_cls_to_wrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    347\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccelerator_config\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43maccelerator_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    348\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdeepspeed\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeepspeed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    349\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabel_smoothing_factor\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    350\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptim\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43moptim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    351\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptim_args\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43moptim_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m    \u001B[49m\u001B[43madafactor\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43madafactor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgroup_by_length\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_by_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlength_column_name\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlength_column_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreport_to\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mreport_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mddp_find_unused_parameters\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mddp_find_unused_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mddp_bucket_cap_mb\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mddp_bucket_cap_mb\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mddp_broadcast_buffers\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mddp_broadcast_buffers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataloader_pin_memory\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_pin_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataloader_persistent_workers\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_persistent_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43mskip_memory_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_memory_metrics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_legacy_prediction_loop\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_legacy_prediction_loop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    363\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpush_to_hub\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mpush_to_hub\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    364\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    365\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhub_model_id\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mhub_model_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    366\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhub_strategy\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mhub_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhub_token\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mhub_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    368\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhub_private_repo\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mhub_private_repo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    369\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhub_always_push\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mhub_always_push\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    370\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgradient_checkpointing\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient_checkpointing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    371\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgradient_checkpointing_kwargs\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient_checkpointing_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    372\u001B[39m \u001B[43m    \u001B[49m\u001B[43minclude_inputs_for_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_inputs_for_metrics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    373\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_do_concat_batches\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_do_concat_batches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    374\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfp16_backend\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp16_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    375\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpush_to_hub_model_id\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mpush_to_hub_model_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    376\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpush_to_hub_organization\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mpush_to_hub_organization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    377\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpush_to_hub_token\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mpush_to_hub_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    378\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmp_parameters\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmp_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[43m    \u001B[49m\u001B[43mauto_find_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mauto_find_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    380\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfull_determinism\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfull_determinism\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtorchdynamo\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorchdynamo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    382\u001B[39m \u001B[43m    \u001B[49m\u001B[43mray_scope\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mray_scope\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[43m    \u001B[49m\u001B[43mddp_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mddp_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    384\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtorch_compile\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_compile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    385\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtorch_compile_backend\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_compile_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtorch_compile_mode\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_compile_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m    \u001B[49m\u001B[43minclude_tokens_per_second\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_tokens_per_second\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m    \u001B[49m\u001B[43minclude_num_input_tokens_seen\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_num_input_tokens_seen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m    \u001B[49m\u001B[43mneftune_noise_alpha\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mneftune_noise_alpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptim_target_modules\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43moptim_target_modules\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_eval_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_eval_metrics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_on_start\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_on_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_liger_kernel\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_liger_kernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_use_gather_object\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_use_gather_object\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    395\u001B[39m \u001B[43m    \u001B[49m\u001B[43maverage_tokens_across_devices\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage_tokens_across_devices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    396\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset_num_proc\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset_num_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    397\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_mini_batches\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_mini_batches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    398\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtotal_episodes\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_episodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    399\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocal_rollout_forward_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_rollout_forward_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    400\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_sample_generations\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_sample_generations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    401\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresponse_length\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    402\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstop_token\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstop_token_id\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    405\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmissing_eos_penalty\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing_eos_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    406\u001B[39m \u001B[43m    \u001B[49m\u001B[43msft_model_path\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43msft_model_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    407\u001B[39m \u001B[43m    \u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    408\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_total_batches\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_total_batches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    409\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmicro_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmicro_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    410\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocal_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    411\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    412\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocal_mini_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_mini_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    413\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmini_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmini_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    414\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexp_name\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mexp_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    415\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreward_model_path\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mreward_model_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    416\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_adapter_name\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_adapter_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    417\u001B[39m \u001B[43m    \u001B[49m\u001B[43mref_adapter_name\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mref_adapter_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    418\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_ppo_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_ppo_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    419\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwhiten_rewards\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhiten_rewards\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    420\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkl_coef\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mkl_coef\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    421\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkl_estimator\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mkl_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    422\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcliprange\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mcliprange\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    423\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvf_coef\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mvf_coef\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    424\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcliprange_value\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mcliprange_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    425\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mgamma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    426\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlam\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlam\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    427\u001B[39m \u001B[43m    \u001B[49m\u001B[43mds3_gather_for_generation\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mds3_gather_for_generation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    428\u001B[39m \u001B[38;5;28mself\u001B[39m.vllm_sampling_params = vllm_sampling_params\n\u001B[32m    429\u001B[39m \u001B[38;5;28mself\u001B[39m.unsloth_num_chunks = unsloth_num_chunks\n",
      "\u001B[31mTypeError\u001B[39m: PPOConfig.__init__() got an unexpected keyword argument 'log_with'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
